{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1dbBg9MU6Opl"
      },
      "outputs": [],
      "source": [
        "#Repositorio en github\n",
        "# https://github.com/Sebastian-Cepeda-Ch/SIS241-Inteligencia-Artificial-II\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKzchuVN8h1o"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, channels_img, featuress_d):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        # Imput: N x channels_img  x 40 x 40\n",
        "        nn.Conv2d(\n",
        "            channels_img, featuress_d, kernel_size= 4, stride=2, padding = 1\n",
        "        ),#20x20\n",
        "        nn.LeakyReLU(0.2),\n",
        "        self._block(featuress_d,featuress_d*2, 4, 2, 1), #10x10\n",
        "        self._block(featuress_d*2,featuress_d*4, 4, 2, 1),#5x5\n",
        "        self._block(featuress_d*4,featuress_d*8, 4, 2, 1),#non\n",
        "    )\n",
        "\n",
        "\n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            bias=False,\n",
        "        ),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, channels_img, features_g):\n",
        "    super(Generator, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        # Input: N x z_dim x 1 x 1\n",
        "        self._block(z_dim, features_g*16, 4, 1, 0), #N x f_g*16 X 4X4\n",
        "        self._block(features_g*16, features_g*8, 4, 2, 1), #8x8\n",
        "        self._block(features_g*8, features_g*4, 4, 2, 1), #16x16\n",
        "        self._block(features_g*4, features_g*2, 4, 2, 1), #32x32\n",
        "        nn.ConvTranspose2d(\n",
        "            features_g*2, channels_img, kernel_size=4, stride=2, padding=1\n",
        "        ), #64x64\n",
        "    )\n",
        "  \n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            bias = False\n",
        "        ),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
